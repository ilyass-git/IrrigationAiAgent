"""
Agent IA LangChain pour la prise de d√©cision d'irrigation
"""
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage
from typing import Dict
import os
import json
import requests
import time
import logging
import re
from config import OPENAI_API_KEY, LLM_MODEL, TEMPERATURE, LLM_PROVIDER, OLLAMA_BASE_URL

logger = logging.getLogger(__name__)


class IrrigationAgent:
    """Agent IA utilisant LangChain pour prendre des d√©cisions d'irrigation"""
    
    def __init__(self):
        """Initialise l'agent avec le mod√®le LLM"""
        
        if LLM_PROVIDER == 'ollama':
            print(f"Utilisation de Ollama avec le modele {LLM_MODEL}")
            try:
                # V√©rifier la disponibilit√© d'Ollama et des mod√®les
                import requests
                try:
                    response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
                    if response.status_code == 200:
                        models = response.json().get('models', [])
                        model_names = [m.get('name', '') for m in models]
                        if model_names:
                            print(f"[INFO] Modeles Ollama disponibles : {', '.join(model_names)}")
                        else:
                            print("[WARNING] Aucun modele Ollama trouve. Assurez-vous d'avoir telecharge un modele avec 'ollama pull <nom_modele>'")
                        
                        # V√©rifier si le mod√®le existe (avec ou sans tag :latest)
                        model_found = LLM_MODEL in model_names
                        if not model_found:
                            # Essayer avec :latest
                            model_with_latest = f"{LLM_MODEL}:latest"
                            if model_with_latest in model_names:
                                print(f"[INFO] Modele '{LLM_MODEL}' trouve comme '{model_with_latest}'")
                                model_found = True
                        
                        if not model_found:
                            print(f"[WARNING] Attention : Le modele '{LLM_MODEL}' n'est pas dans la liste des modeles disponibles.")
                            if model_names:
                                print(f"[INFO] Suggestion : Utilisez l'un de ces modeles : {', '.join(model_names)}")
                except requests.exceptions.RequestException as e:
                    print(f"[WARNING] Impossible de se connecter a Ollama sur {OLLAMA_BASE_URL}")
                    print(f"   Erreur : {e}")
                    print(f"   Assurez-vous qu'Ollama est demarre : 'ollama serve'")
                
                self.llm = ChatOllama(
                    model=LLM_MODEL,
                    temperature=TEMPERATURE,
                    base_url=OLLAMA_BASE_URL,
                    timeout=30.0  # Timeout de 30 secondes pour Ollama
                )
            except Exception as e:
                print(f"[ERROR] Erreur lors de l'initialisation d'Ollama : {e}")
                raise
        else:
            # S'assurer que la cl√© API est dans l'environnement pour OpenAI
            if OPENAI_API_KEY:
                os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
            
            self.llm = ChatOpenAI(
                model=LLM_MODEL,
                temperature=TEMPERATURE,
                timeout=30.0  # Timeout de 30 secondes pour OpenAI
            )
        
        # Template de prompt syst√®me pour guider l'agent
        self.system_prompt = """Tu es un expert en agriculture intelligente et en gestion de l'irrigation.

Ta mission est d'analyser les conditions m√©t√©orologiques actuelles, les donn√©es de capteurs IoT et les retours d'experts pour prendre une d√©cision √©clair√©e : IRRIGUER ou NE PAS IRRIGUER.

CRIT√àRES DE D√âCISION (par ordre de priorit√©) :
1. **HUMIDIT√â DU SOL** (CAPTEUR) - LE FACTEUR LE PLUS IMPORTANT :
   - < 25% = ALERTE CRITIQUE ‚Üí IRRIGUER IMM√âDIATEMENT
   - 25-30% = Sol sec ‚Üí IRRIGUER
   - 30-40% = Sol l√©g√®rement sec ‚Üí IRRIGUER si autres conditions favorables
   - 40-60% = Sol optimal ‚Üí NE PAS IRRIGUER sauf si √©vapotranspiration √©lev√©e
   - 60-70% = Sol bien hydrat√© ‚Üí NE PAS IRRIGUER
   - > 70% = Sol satur√© ‚Üí NE PAS IRRIGUER (risque de pourriture)

2. **NIVEAU DU R√âSERVOIR** (CAPTEUR) :
   - < 20% = Irrigation impossible ‚Üí NE PAS IRRIGUER (r√©servoir vide)
   - 20-30% = Niveau faible ‚Üí IRRIGUER seulement si sol tr√®s sec (< 25%)
   - > 30% = R√©servoir suffisant ‚Üí Peut irriguer si n√©cessaire

3. **√âVAPOTRANSPIRATION** (CAPTEUR) :
   - √âlev√©e (> 8 mm/jour) + sol sec ‚Üí IRRIGUER
   - Faible (< 3 mm/jour) ‚Üí Besoins r√©duits

4. **Conditions m√©t√©orologiques** :
   - Ne pas irriguer si pluviom√©trie r√©cente ou pr√©vue > 5mm
   - Ne pas irriguer si humidit√© de l'air > 80%
   - Temp√©rature √©lev√©e ‚Üí Besoins en eau augmentent

4. **Retours d'experts (REVUES)** :
   - √âtudier les critiques pass√©es : si plusieurs revues r√©centes sont n√©gatives (<3‚≠ê), √©viter de reproduire les m√™mes conditions
   - Donner davantage de poids aux retours positifs (>4‚≠ê) lorsque les conditions sont similaires
   - Si la note moyenne des revues r√©centes est < 3‚≠ê, √™tre plus prudent dans la d√©cision

R√àGLES IMPORTANTES :
- L'HUMIDIT√â DU SOL EST LE FACTEUR D√âCISIF - prioriser cette donn√©e
- Ne jamais irriguer si le r√©servoir est < 20%
- Ne pas irriguer si le sol est d√©j√† satur√© (> 70%)
- Prendre en compte les alertes des capteurs
- Mentionner explicitement lorsqu'une d√©cision suit (ou contredit) les retours d'experts
- SI TU D√âCIDES D'IRRIGUER, CHOISIS UNE DUR√âE D'IRRIGATION (10 √† 60 minutes). Plus le sol est sec ou l'√©vapotranspiration √©lev√©e, plus la dur√©e doit augmenter. Si la d√©cision est NE PAS IRRIGUER, la dur√©e doit imp√©rativement √™tre 0.

GUIDE RAPIDE POUR LA DUR√âE :
- Humidit√© < 25 % ‚Üí 45 √† 60 min
- Entre 25 % et 35 % ‚Üí 30 √† 40 min
- Entre 35 % et 45 % ‚Üí 20 √† 30 min
- > 45 % ou pluie pr√©vue ‚Üí 0 √† 15 min maximum
R√©duis la dur√©e si le niveau du r√©servoir est bas ou si les experts ont r√©cemment critiqu√© des dur√©es trop longues.

FORMAT DE R√âPONSE :
Tu dois r√©pondre UNIQUEMENT avec un JSON valide, SANS texte avant ou apr√®s, SANS markdown, SANS doubles accolades.
Format exact √† utiliser (copier-coller et remplacer les valeurs) :

{
    "decision": "IRRIGUER",
    "duree_minutes": 30,
    "explication": "Explication en fran√ßais"
}

OU

{
    "decision": "NE PAS IRRIGUER",
    "duree_minutes": 0,
    "explication": "Explication en fran√ßais"
}

IMPORTANT : 
- R√©ponds UNIQUEMENT le JSON, rien d'autre
- Utilise des accolades simples { et }, PAS de doubles {{ ou }}
- Pas de texte avant ou apr√®s le JSON
- Pas de markdown ```json
"""
    
    def make_decision(self, weather_summary: str, 
                     sensor_summary: str = "", sensor_alerts: list = None,
                     reviews_summary: str = "") -> Dict:
        """
        Prend une d√©cision d'irrigation bas√©e sur les donn√©es fournies
        
        Args:
            weather_summary: R√©sum√© des conditions m√©t√©o actuelles
            sensor_summary: R√©sum√© des donn√©es de capteurs IoT
            sensor_alerts: Liste des alertes des capteurs
            reviews_summary: R√©sum√© des retours d'experts (notes et commentaires)
        
        Returns:
            Dictionnaire contenant la d√©cision, la dur√©e et l'explication
        """
        start_time = time.time()
        logger.info("[AGENT] D√©but de l'analyse par l'IA...")
        
        if sensor_alerts is None:
            sensor_alerts = []
        
        # Construction du message avec alertes
        alerts_text = ""
        if sensor_alerts:
            alerts_text = "\nüö® ALERTES DES CAPTEURS :\n" + "\n".join(sensor_alerts) + "\n"
        
        try:
            # Construction du prompt
            prompt_start = time.time()
            # Construire le message sans f-string pour √©viter les probl√®mes avec les accolades
            prompt_content = f"""DONN√âES √Ä ANALYSER :

{weather_summary}

{sensor_summary}

{alerts_text}

{reviews_summary}

Prends maintenant ta d√©cision en analysant ces informations. PRIORISE les donn√©es de capteurs, surtout l'humidit√© du sol. Prends en compte les retours d'experts (notes des reviews). 

R√âPONDS UNIQUEMENT AVEC LE JSON, SANS TEXTE AVANT OU APR√àS, SANS MARKDOWN, SANS DOUBLES ACCOLADES. Format exact :

{{
    "decision": "IRRIGUER" ou "NE PAS IRRIGUER",
    "duree_minutes": nombre entier,
    "explication": "ton explication"
}}"""
            
            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=prompt_content)
            ]
            prompt_duration = time.time() - prompt_start
            logger.info(f"[AGENT] Prompt construit en {prompt_duration:.3f}s")
            
            # Appel au LLM
            logger.info(f"[AGENT] Appel au LLM ({LLM_PROVIDER}/{LLM_MODEL})...")
            llm_start = time.time()
            response = self.llm.invoke(messages)
            llm_duration = time.time() - llm_start
            logger.info(f"[AGENT] ‚úì R√©ponse LLM re√ßue en {llm_duration:.2f}s")
            
            # Extraction de la r√©ponse
            response_text = response.content.strip()
            logger.info(f"[AGENT] R√©ponse brute (premiers 300 chars): {response_text[:300]}...")
            
            # Nettoyage de la r√©ponse (enlever les markdown code blocks si pr√©sents)
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            response_text = response_text.strip()
            
            # Correction des doubles accolades (probl√®me avec certains LLM)
            # Remplacer {{ par { et }} par }
            response_text = response_text.replace('{{', '{').replace('}}', '}')
            
            # Essayer d'extraire le JSON si la r√©ponse contient du texte avant/apr√®s
            # Chercher le premier { et le dernier }
            first_brace = response_text.find('{')
            last_brace = response_text.rfind('}')
            if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                response_text = response_text[first_brace:last_brace+1]
                logger.info(f"[AGENT] JSON extrait de la r√©ponse (position {first_brace}-{last_brace})")
            
            # Parsing du JSON
            parse_start = time.time()
            try:
                decision_data = json.loads(response_text)
            except json.JSONDecodeError as json_err:
                logger.error(f"[AGENT] Erreur de parsing JSON apr√®s nettoyage: {json_err}")
                logger.error(f"[AGENT] Texte nettoy√©: {response_text[:500]}")
                raise
            parse_duration = time.time() - parse_start
            logger.info(f"[AGENT] ‚úì JSON pars√© en {parse_duration:.3f}s")
            
            # Validation
            if 'decision' not in decision_data or 'explication' not in decision_data:
                raise ValueError("Format de r√©ponse invalide: champs manquants")
            
            if decision_data['decision'] not in ['IRRIGUER', 'NE PAS IRRIGUER']:
                raise ValueError(f"D√©cision invalide: '{decision_data['decision']}'")
            
            duree = int(decision_data.get('duree_minutes', 0) or 0)
            logger.info(f"[AGENT] Dur√©e brute du LLM: {duree} min")
            
            if duree < 0:
                duree = 0
                logger.info(f"[AGENT] Dur√©e n√©gative corrig√©e √† 0")
            
            if decision_data['decision'] == 'NE PAS IRRIGUER':
                duree = 0
                logger.info(f"[AGENT] Dur√©e mise √† 0 car d√©cision = NE PAS IRRIGUER")
            else:
                duree = max(10, min(60, duree)) if duree > 0 else 20
                logger.info(f"[AGENT] Dur√©e ajust√©e entre 10-60 min: {duree} min")
            
            decision_data['duree_minutes'] = duree
            
            total_duration = time.time() - start_time
            logger.info(f"[AGENT] ‚úì D√©cision finale: {decision_data['decision']}, Dur√©e: {duree} min (total: {total_duration:.2f}s)")
            
            return decision_data
            
        except json.JSONDecodeError as e:
            logger.error(f"[AGENT] Erreur de parsing JSON : {e}")
            logger.error(f"[AGENT] R√©ponse re√ßue : {response_text[:500]}")
            # Fallback : essayer d'extraire la d√©cision manuellement
            logger.warning("[AGENT] Utilisation du fallback pour extraire la d√©cision")
            return self._extract_decision_fallback(response_text)
        except Exception as e:
            error_msg = str(e)
            total_duration = time.time() - start_time
            logger.error(f"[AGENT] Erreur apr√®s {total_duration:.2f}s : {error_msg}", exc_info=True)
            
            # Messages d'erreur plus explicites pour Ollama
            if 'not found' in error_msg.lower() or '404' in error_msg:
                error_msg = f"Mod√®le '{LLM_MODEL}' non trouv√© dans Ollama. V√©rifiez que le mod√®le est install√© avec 'ollama pull {LLM_MODEL}'"
            elif 'connection' in error_msg.lower() or 'refused' in error_msg.lower():
                error_msg = f"Impossible de se connecter √† Ollama sur {OLLAMA_BASE_URL}. Assurez-vous qu'Ollama est d√©marr√©."
            
            logger.warning(f"[AGENT] Retour d'une d√©cision s√©curis√©e: NE PAS IRRIGUER")
            return {
                'decision': 'NE PAS IRRIGUER',
                'duree_minutes': 0,
                'explication': f'Erreur lors de l\'analyse : {error_msg}. Par pr√©caution, l\'irrigation n\'est pas activ√©e.'
            }
    
    def _extract_decision_fallback(self, response_text: str) -> Dict:
        """
        M√©thode de fallback pour extraire la d√©cision si le JSON est mal format√©
        
        Args:
            response_text: Texte de r√©ponse du LLM
        
        Returns:
            Dictionnaire avec la d√©cision extraite
        """
        logger.info("[AGENT] Extraction fallback de la d√©cision...")
        decision = 'NE PAS IRRIGUER'  # Par d√©faut, s√©curit√©
        explication = response_text
        duree = 0
        
        # Essayer d'extraire le JSON m√™me s'il est mal format√©
        # Chercher "decision" dans le texte
        import re
        
        # Chercher "decision": "IRRIGUER" ou "decision": "NE PAS IRRIGUER"
        decision_pattern = r'"decision"\s*:\s*"([^"]+)"'
        decision_match = re.search(decision_pattern, response_text, re.IGNORECASE)
        
        if decision_match:
            decision_found = decision_match.group(1).strip().upper()
            logger.info(f"[AGENT] D√©cision trouv√©e dans JSON: '{decision_found}'")
            
            if decision_found == 'IRRIGUER':
                decision = 'IRRIGUER'
            elif 'NE PAS IRRIGUER' in decision_found or 'NE_PAS_IRRIGUER' in decision_found:
                decision = 'NE PAS IRRIGUER'
            else:
                logger.warning(f"[AGENT] D√©cision inconnue: '{decision_found}', utilisation par d√©faut")
        else:
            # Si pas trouv√© dans JSON, chercher dans le texte mais de mani√®re plus pr√©cise
            # Chercher "NE PAS IRRIGUER" en premier (plus sp√©cifique)
            if 'NE PAS IRRIGUER' in response_text.upper() or '"NE PAS IRRIGUER"' in response_text.upper():
                decision = 'NE PAS IRRIGUER'
                logger.info("[AGENT] D√©cision extraite du texte: NE PAS IRRIGUER")
            elif '"IRRIGUER"' in response_text.upper() or (response_text.upper().startswith('IRRIGUER') and 'NE PAS' not in response_text.upper()[:50]):
                # V√©rifier que "IRRIGUER" n'est pas dans une explication n√©gative
                # Chercher le contexte autour de "IRRIGUER"
                irriguer_pos = response_text.upper().find('IRRIGUER')
                if irriguer_pos != -1:
                    context_before = response_text[max(0, irriguer_pos-30):irriguer_pos].upper()
                    if 'NE PAS' not in context_before and 'NOT' not in context_before:
                        decision = 'IRRIGUER'
                        logger.info("[AGENT] D√©cision extraite du texte: IRRIGUER")
                    else:
                        decision = 'NE PAS IRRIGUER'
                        logger.info("[AGENT] 'IRRIGUER' trouv√© mais dans un contexte n√©gatif, d√©cision: NE PAS IRRIGUER")
            else:
                logger.warning("[AGENT] D√©cision non trouv√©e clairement, utilisation par d√©faut s√©curis√©e: NE PAS IRRIGUER")
        
        # Essayer d'extraire la dur√©e aussi
        duree_pattern = r'"duree_minutes"\s*:\s*(\d+)'
        duree_match = re.search(duree_pattern, response_text, re.IGNORECASE)
        if duree_match:
            try:
                duree = int(duree_match.group(1))
                logger.info(f"[AGENT] Dur√©e extraite du JSON: {duree} min")
            except ValueError:
                pass
        
        # Si d√©cision = NE PAS IRRIGUER, dur√©e doit √™tre 0
        if decision == 'NE PAS IRRIGUER':
            duree = 0
        
        logger.info(f"[AGENT] D√©cision fallback finale: {decision}, Dur√©e: {duree} min")
        
        return {
            'decision': decision,
            'duree_minutes': duree,
            'explication': explication
        }

